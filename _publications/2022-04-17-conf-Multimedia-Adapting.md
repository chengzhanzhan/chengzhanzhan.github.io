---
title: "Adapting on Long-Tail Domains by High Quality Self-training for Object Detection"
collection: publications
category: conferences
permalink: /publication/2022-04-17-conf-Multimedia-Adapting
excerpt: 'Duo Li, Sanli Tang, Binbin Zhang, Zhanzhan Cheng, Wenming Tan, Xiaokang Yang'
date: 2022-04-17
venue: 'International Forum on Digital TV and Wireless Multimedia Communications'
#slidesurl: 'http://academicpages.github.io/files/slides3.pdf'
paperurl: 'https://link.springer.com/chapter/10.1007/978-981-19-2266-4_19'
#citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---

Authors:
------
Duo Li, Sanli Tang, Binbin Zhang, Zhanzhan Cheng, Wenming Tan, Xiaokang Yang

Abstract:
------
Domain shift is a critical challenge when we deploy object detectors to real world applications. Due to the data distribution misalignment between the source and target domains, the detector suffers from a significant performance drop on the target domain. In some situations, the target domain contains a large ratio of objects in a few categories. This long-tail distribution makes it even harder to transfer well from source to target. In this paper, we tackle this categorical distribution difference in domain adaptation using self-training, where the unlabeled images in target domain are tagged with pseudo-labels to train the detector itself. To promote the effect of self-training, we propose SEAT (Score Ensemble and Adaptive Threshold), where high quality pseudo-labeled samples are elected by comprehensively analyzing information from multiple aspects. We show that these high quality pseudo-labeled training samples play a critical role in dealing with categorical distribution difference. Experiments on public data sets show the effectiveness of our method.

[Download Paper](https://link.springer.com/chapter/10.1007/978-981-19-2266-4_19)