---
title: "Reading order detection in visually-rich documents with multi-modal layout-aware relation prediction"
collection: publications
category: journal
permalink: /publication/2024-06-01-jour-PR-Reading
excerpt: 'Liang Qiao, Can Li, Zhanzhan Cheng*, Yunlu Xu, Yi Niu, Xi Li'
date: 2024-06-01
venue: 'Pattern Recognition'
#slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://www.sciencedirect.com/science/article/abs/pii/S0031320324000657'
#bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
Authors:
------
Liang Qiao, Can Li, Zhanzhan Cheng*, Yunlu Xu, Yi Niu, Xi Li

Abstract:
------
Reading order detection aims to arrange the text logically, which is essential in understanding visual documents. Current methods mostly model the problem as a sequence generation task, which use insufficient modalities information ignore the various reading habits under different document layouts, leading to the lack of robustness for some complex scenarios. To address these challenges, we present a novel approach with the Multi-Modal Layout-Aware Relation Prediction. It employs a straightforward yet highly effective task formulation for predicting the order relation between text instances. Our model leverages visual, semantic, and positional features, with the positional features being adaptively generated through a layout-aware position embedding module. Then, different modality features are enhanced via a two-staged position-guided multi-modal fusion module. Additionally, we introduce two novel loss functions, Degree Loss and Cycle Loss, to effectively impose network constraints at multiple levels. Our experimental results, conducted on three real-world datasets, demonstrate that our proposed method achieves a new state-of-the-art level of performance.

[Download Paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320324000657)